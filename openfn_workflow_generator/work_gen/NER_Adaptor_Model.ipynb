{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHL89QP8LV7z",
        "outputId": "6189cfc5-5be7-4fef-9251-10ad726dcc07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.4\n",
            "    Uninstalling spacy-3.7.4:\n",
            "      Successfully uninstalled spacy-3.7.4\n",
            "Successfully installed spacy-3.7.5\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy\n",
        "!pip install -U spacy spacy-lookups-data  # Ensure lookups are installed\n",
        "!python -m spacy download en_core_web_sm   # Download language model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training import Example\n",
        "import json\n",
        "\n",
        "# Load your labeled data\n",
        "TRAIN_DATA = [\n",
        "    {\"text\": \"Fetch Referrals From Primero using the primero adaptor\", \"entities\": [(26, 33, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send a text message to case officer with telerivet adaptor\", \"entities\": [(41, 50, \"ADAPTER\")]},\n",
        "    {\"text\": \"Add patient to DHIS2 with the dhis2 adaptor\", \"entities\": [(17, 22, \"ADAPTER\")]},\n",
        "    {\"text\": \"Get Data from DHIS2\", \"entities\": [(14, 19, \"ADAPTER\")]},\n",
        "    {\"text\": \"Fetch submissions from KoboCollect with language-kobotoolbox@latest\", \"entities\": [(29, 57, \"ADAPTER\")]},\n",
        "    {\"text\": \"Push the data to the a postgresSQL database with language-postgresql@latest\", \"entities\": [(44, 71, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send text message to an admin using language-twilio@0.3.4 with status of sent message\", \"entities\": [(34, 54, \"ADAPTER\")]},\n",
        "    {\"text\": \"FHIR standard Data with change\", \"entities\": [(0, 4, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send to OpenHIM to route to SHR\", \"entities\": [(8, 15, \"ADAPTER\")]},\n",
        "    {\"text\": \"Notify CHW on upload successful\", \"entities\": []},\n",
        "    {\"text\": \"Fetch immunization data from OpenMRS using the openmrs adaptor.\", \"entities\": [(39,46, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send an appointment reminder SMS via Twilio.\", \"entities\": [(32,38, \"ADAPTER\")]},\n",
        "    {\"text\": \"Update stock levels in the warehouse management system using the dynamics adaptor.\", \"entities\": [(63,71, \"ADAPTER\")]},\n",
        "    {\"text\": \"Get a list of active cases from CommCare.\", \"entities\": [(31,39, \"ADAPTER\")]},\n",
        "    {\"text\": \"Aggregate survey responses and create a report in Google Sheets.\", \"entities\": [(55,67, \"ADAPTER\")]},\n",
        "    {\"text\": \"The workflow triggers when a new patient is registered in OpenMRS.\", \"entities\": [(63,69, \"ADAPTER\")]},\n",
        "    {\"text\": \"Export the data to a CSV file on the SFTP server.\", \"entities\": [(36,40, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send an email alert to the supervisor using the mailgun adaptor.\", \"entities\": [(46,53, \"ADAPTER\")]},\n",
        "    {\"text\": \"The job polls the inbox for new messages using the IMAP protocol.\", \"entities\": []},\n",
        "    {\"text\": \"Retrieve patient demographics from the FHIR server.\", \"entities\": [(35,40, \"ADAPTER\")]},\n",
        "    {\"text\": \"Push the updated records to the Salesforce CRM.\", \"entities\": [(33,42, \"ADAPTER\")]},\n",
        "    {\"text\": \"Create a new task in Asana when a case is closed.\", \"entities\": [(21,26, \"ADAPTER\")]},\n",
        "    {\"text\": \"The job runs every hour to synchronize data between OpenMRS and DHIS2.\", \"entities\": [(43,49, \"ADAPTER\"), (63,68, \"ADAPTER\")]},\n",
        "    {\"text\": \"Store the processed data in Azure Blob Storage.\", \"entities\": [(33,46, \"ADAPTER\")]},\n",
        "    {\"text\": \"Fetch Referrals From Primero using the primero adaptor.\", \"entities\": [(29,36, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send a text message to case officer with telerivet adaptor.\", \"entities\": [(40,48, \"ADAPTER\")]},\n",
        "    {\"text\": \"Add patient to DHIS2 with the dhis2 adaptor.\", \"entities\": [(25,30, \"ADAPTER\")]},\n",
        "    {\"text\": \"Get Data from DHIS2.\", \"entities\": [(12,17, \"ADAPTER\")]},\n",
        "    {\"text\": \"Filter out children under 2.\", \"entities\": []},\n",
        "    {\"text\": \"Aggregate the data.\", \"entities\": []},\n",
        "    {\"text\": \"Make a comment on Asana.\", \"entities\": [(18,23, \"ADAPTER\")]},\n",
        "    {\"text\": \"Fetch submissions from KoboCollect with language-kobotoolbox@latest.\", \"entities\": [(27,37, \"ADAPTER\")]},\n",
        "    {\"text\": \"Push the data to the a postgresSQL database with language-postgresql@latest.\", \"entities\": [(43,54, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send text message to an admin using language-twilio@0.3.4 with status of sent message.\", \"entities\": [(28,34, \"ADAPTER\")]},\n",
        "    {\"text\": \"FHIR standard Data with change.\", \"entities\": [(0,4, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send to OpenHIM to route to SHR.\", \"entities\": [(6,13, \"ADAPTER\")]},\n",
        "    {\"text\": \"Notify CHW on upload successful.\", \"entities\": []},\n",
        "\n",
        "]\n",
        "\n",
        "# Load the English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Get the existing NER component\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Add your custom \"ADAPTER\" label\n",
        "ner.add_label(\"ADAPTER\")\n",
        "\n",
        "# Get names of other pipes to disable them during training\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "\n",
        "# Convert TRAIN_DATA into spaCy's Example format\n",
        "examples = []\n",
        "for entry in TRAIN_DATA:\n",
        "    doc = nlp.make_doc(entry[\"text\"])\n",
        "    example = Example.from_dict(doc, {\"entities\": entry[\"entities\"]})\n",
        "    examples.append(example)\n",
        "\n",
        "# Training loop\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.begin_training()\n",
        "    for itn in range(30):\n",
        "        losses = {}\n",
        "        nlp.update(examples, sgd=optimizer, drop=0.5, losses=losses)\n",
        "        print(losses)\n",
        "\n",
        "# Save the trained model\n",
        "nlp.to_disk(\"openfn_adaptor_ner\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3B_r6cBLcB9",
        "outputId": "78d4a1a9-064c-4c6e-d685-44743a290b2d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Fetch immunization data from OpenMRS using the ope...\" with entities \"[(39, 46, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Send an appointment reminder SMS via Twilio.\" with entities \"[(32, 38, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Update stock levels in the warehouse management sy...\" with entities \"[(63, 71, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Get a list of active cases from CommCare.\" with entities \"[(31, 39, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Aggregate survey responses and create a report in ...\" with entities \"[(55, 67, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The workflow triggers when a new patient is regist...\" with entities \"[(63, 69, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Export the data to a CSV file on the SFTP server.\" with entities \"[(36, 40, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Send an email alert to the supervisor using the ma...\" with entities \"[(46, 53, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Retrieve patient demographics from the FHIR server...\" with entities \"[(35, 40, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Push the updated records to the Salesforce CRM.\" with entities \"[(33, 42, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The job runs every hour to synchronize data betwee...\" with entities \"[(43, 49, 'ADAPTER'), (63, 68, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Store the processed data in Azure Blob Storage.\" with entities \"[(33, 46, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Fetch Referrals From Primero using the primero ada...\" with entities \"[(29, 36, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Send a text message to case officer with telerivet...\" with entities \"[(40, 48, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Add patient to DHIS2 with the dhis2 adaptor.\" with entities \"[(25, 30, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Get Data from DHIS2.\" with entities \"[(12, 17, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Fetch submissions from KoboCollect with language-k...\" with entities \"[(27, 37, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Push the data to the a postgresSQL database with l...\" with entities \"[(43, 54, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Send text message to an admin using language-twili...\" with entities \"[(28, 34, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Send to OpenHIM to route to SHR.\" with entities \"[(6, 13, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ner': 205.6281982064247}\n",
            "{'ner': 283.8307536840439}\n",
            "{'ner': 282.25145041942596}\n",
            "{'ner': 280.29306530952454}\n",
            "{'ner': 277.8500675559044}\n",
            "{'ner': 274.01862996816635}\n",
            "{'ner': 267.0271247625351}\n",
            "{'ner': 256.2230362892151}\n",
            "{'ner': 242.96135061979294}\n",
            "{'ner': 229.35395222902298}\n",
            "{'ner': 205.17218679189682}\n",
            "{'ner': 165.34327974915504}\n",
            "{'ner': 125.06622034311295}\n",
            "{'ner': 82.66953518986702}\n",
            "{'ner': 48.96430659946054}\n",
            "{'ner': 26.00176438409835}\n",
            "{'ner': 17.869213992076766}\n",
            "{'ner': 15.286856625580754}\n",
            "{'ner': 13.833499010508831}\n",
            "{'ner': 14.204669126926117}\n",
            "{'ner': 13.587861774294367}\n",
            "{'ner': 12.913761688272542}\n",
            "{'ner': 13.941888034094402}\n",
            "{'ner': 13.920258282306698}\n",
            "{'ner': 13.429053491580554}\n",
            "{'ner': 13.482031210337368}\n",
            "{'ner': 13.244044155996221}\n",
            "{'ner': 13.124295731281109}\n",
            "{'ner': 12.231331663773744}\n",
            "{'ner': 12.844756205449812}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training import Example\n",
        "from spacy.scorer import Scorer\n",
        "\n",
        "def evaluate(ner_model, examples):\n",
        "    scorer = Scorer()\n",
        "    scored_examples = [] # Empty list to store scored examples\n",
        "    for example in examples:\n",
        "        pred_doc = ner_model(example.reference.text)\n",
        "        example.predicted = pred_doc\n",
        "        scored_examples.append(example) # Append to the list\n",
        "    return scorer.score(scored_examples)  # Pass the list of scored examples\n",
        "\n",
        "\n",
        "# Load the evaluation data\n",
        "eval_data = [\n",
        "    {\"text\": \"Fetch Referrals From Primero using the primero adaptor\", \"entities\": [(26, 33, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send a text message to case officer with telerivet adaptor\", \"entities\": [(41, 50, \"ADAPTER\")]},\n",
        "    {\"text\": \"Add patient to DHIS2 with the dhis2 adaptor\", \"entities\": [(17, 22, \"ADAPTER\")]},\n",
        "    {\"text\": \"Get Data from DHIS2\", \"entities\": [(14, 19, \"ADAPTER\")]},\n",
        "    {\"text\": \"Fetch submissions from KoboCollect with language-kobotoolbox@latest\", \"entities\": [(29, 57, \"ADAPTER\")]},\n",
        "    {\"text\": \"Push the data to the a postgresSQL database with language-postgresql@latest\", \"entities\": [(44, 71, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send text message to an admin using language-twilio@0.3.4 with status of sent message\", \"entities\": [(34, 54, \"ADAPTER\")]},\n",
        "    {\"text\": \"FHIR standard Data with change\", \"entities\": [(0, 4, \"ADAPTER\")]},\n",
        "    {\"text\": \"Send to OpenHIM to route to SHR\", \"entities\": [(8, 15, \"ADAPTER\")]},\n",
        "    {\"text\": \"Notify CHW on upload successful\", \"entities\": []}\n",
        "]\n",
        "\n",
        "# Load the trained model\n",
        "nlp = spacy.load(\"openfn_adaptor_ner\")\n",
        "\n",
        "# Prepare evaluation examples\n",
        "examples = []\n",
        "for entry in eval_data:\n",
        "    doc = nlp.make_doc(entry[\"text\"])\n",
        "    example = Example.from_dict(doc, {\"entities\": entry[\"entities\"]})\n",
        "    examples.append(example)\n",
        "\n",
        "# Evaluate the model\n",
        "scores = evaluate(nlp, examples)\n",
        "print(scores)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEkpacGKCTMB",
        "outputId": "76942b16-3aeb-4e24-e615-56f9323a0505"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Fetch Referrals From Primero using the primero ada...\" with entities \"[(26, 33, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Add patient to DHIS2 with the dhis2 adaptor\" with entities \"[(17, 22, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Fetch submissions from KoboCollect with language-k...\" with entities \"[(29, 57, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Push the data to the a postgresSQL database with l...\" with entities \"[(44, 71, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Send text message to an admin using language-twili...\" with entities \"[(34, 54, 'ADAPTER')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'sents_p': None, 'sents_r': None, 'sents_f': None, 'tag_acc': None, 'pos_acc': None, 'morph_acc': None, 'morph_micro_p': None, 'morph_micro_r': None, 'morph_micro_f': None, 'morph_per_feat': None, 'dep_uas': None, 'dep_las': None, 'dep_las_per_type': None, 'ents_p': 0.0, 'ents_r': 0.0, 'ents_f': 0.0, 'ents_per_type': {'ADAPTER': {'p': 0.0, 'r': 0.0, 'f': 0.0}}, 'cats_score': 0.0, 'cats_score_desc': 'macro F', 'cats_micro_p': 0.0, 'cats_micro_r': 0.0, 'cats_micro_f': 0.0, 'cats_macro_p': 0.0, 'cats_macro_r': 0.0, 'cats_macro_f': 0.0, 'cats_macro_auc': 0.0, 'cats_f_per_type': {}, 'cats_auc_per_type': {}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJlfkwJHFCxV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}